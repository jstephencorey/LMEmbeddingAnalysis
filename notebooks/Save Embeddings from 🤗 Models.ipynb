{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'F:/Dev/LMEmbeddingAnalysis/') # Change to what you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.nn import Embedding\n",
    "\n",
    "from utils.constants import HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"t5-v1_1-small\",\n",
    "    \"t5-v1_1-base\",\n",
    "    \"t5-v1_1-large\",\n",
    "    \"t5-v1_1-xl\",\n",
    "    \"t5-v1_1-xxl\",\n",
    "]\n",
    "\n",
    "model_paths = [ # the location of the saved models on my machine. You could also make this ðŸ¤— ids, e.g. google/t5-v1_1-small. You may need to change more of the code, though.\n",
    "    \"F:/Models/google/\" + model_name + \"\" for model_name in model_names\n",
    "]\n",
    "\n",
    "model_filenames = [ # this is the simplest way to deal with multipart files when I just need the first one (the embedding is just in the first one)\n",
    "    \"pytorch_model.bin\",\n",
    "    \"pytorch_model.bin\",\n",
    "    \"pytorch_model.bin\",\n",
    "    \"pytorch_model.bin\",\n",
    "    \"pytorch_model.bin\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.embed_tokens.weight\n"
     ]
    }
   ],
   "source": [
    "weights = torch.load(model_paths[0] + \"/\" + model_filenames[0], map_location='cpu')\n",
    "weight_key = list(weights.keys())[1] # May not be 1, may be 0 or something else\n",
    "print(weight_key) # Make sure this is what you want! It'll probably say \"embed\" somewhere, and is different for each model suite, and even sometimes for models within the model suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32128 512\n",
      "torch.Size([512])\n",
      "tensor([[-1.2188e+00, -4.3750e+00, -7.9062e+00,  ...,  2.0469e+00,\n",
      "          3.0938e+00, -6.5938e+00],\n",
      "        [-1.4438e+01,  8.1250e+00, -1.1719e+00,  ...,  1.1562e+01,\n",
      "          4.8438e+00,  9.1000e+01],\n",
      "        [ 8.1250e+00,  3.6250e+00, -1.9453e+00,  ..., -4.6250e+00,\n",
      "          1.3125e+01,  2.1375e+01],\n",
      "        ...,\n",
      "        [-4.5117e-01, -3.3594e-01, -3.8867e-01,  ..., -2.0996e-01,\n",
      "         -2.0000e+00, -9.1406e-01],\n",
      "        [-1.0234e+00, -8.0859e-01,  4.3555e-01,  ..., -5.9326e-02,\n",
      "         -9.2188e-01, -9.2969e-01],\n",
      "        [ 1.0078e+00,  1.5234e-01, -2.4902e-01,  ..., -1.8555e-01,\n",
      "         -2.7148e-01,  1.7969e+00]])\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_path, model_filename in zip(model_names, model_paths, model_filenames):\n",
    "    if model_name in [ # Easy way to select precisely the ones you need. Some files are weird and have different weight keys even for the same model suite\n",
    "        \"t5-v1_1-base\",\n",
    "        \"t5-v1_1-large\",\n",
    "        \"t5-v1_1-xl\",\n",
    "        \"t5-v1_1-xxl\",\n",
    "    ]:\n",
    "        continue\n",
    "    embedding_filename = f'../embeddings/{model_name}.pth'\n",
    "\n",
    "    config_filename = model_path + '/config.json'\n",
    "    with open(config_filename) as file:\n",
    "        config_dict = json.loads(file.read())\n",
    "        vocab_side = config_dict['vocab_size']\n",
    "        d_model = config_dict['d_model']\n",
    "        print(vocab_side,d_model)\n",
    "        embedding_layer = Embedding(vocab_side, d_model)\n",
    "        print(embedding_layer(torch.tensor(0)).size())\n",
    "        \n",
    "    weights = torch.load(model_path + \"/\" + model_filename, map_location='cpu')  # Adjust path as needed\n",
    "    # print(weights.keys())\n",
    "    print(weights['encoder.embed_tokens.weight'])\n",
    "    embedding_layer.load_state_dict({\"weight\":weights['encoder.embed_tokens.weight']}) \n",
    "    # print(embedding_layer.weight[0])\n",
    "\n",
    "    torch.save(embedding_layer, embedding_filename, pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-cuda4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
